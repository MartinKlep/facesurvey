<html>
    <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://www.youtube.com/iframe_api"></script>
        <script defer src="face-api.min.js"></script>
        
        <link rel="stylesheet" href="https://www.konstantinsteinle.de/soscisurvey/css/soscisurvey.css" />
        <style>
            
            p {
                color: black;
                text-align: center;
                font-weight: bold;
                font-size: 50px; 
            }
            button {
            color: white;
            background-color: red;
            padding: 15px 32px;
            text-align: center;
            display: inline-block;
            font-size: 20px;
            margin: 4px 2px;
            cursor: pointer;
            position: static;
            }

        </style>
    </head>
    <body style="background-color:lightgrey;">
        <title>Face Survey Test</title>

        <p id="title">Face Survey Test</p>

        

       <script>
        var player;
        var data = [];
        var relevantData = [];
        const timeOfInterest = 16; // input interest time in seconds
        
        
        function onYouTubeIframeAPIReady() {
        player = new YT.Player('player', {
          height: '443',
          width: '788.54',
          iv_load_policy: '3',
          showinfo: '0',
          rel: '0',
          cc_load_policy: '0',
          playsinline: '1',
          showinfo : '0',
          videoId: 'cOrHAtZqIY8',       // CHANGE VIDEO HERE
          events: {
            'onReady': onPlayerReady
          }
        });
      }

      function onPlayerReady(event){
            document.getElementById("btn").disabled = false;
            console.log("player is ready");
        }

        var endVideo;

        function play(){
            console.log("clicked start");
            player.seekTo(timeOfInterest-5,true);
            player.playVideo();
            var endVideo = setInterval(autoStopVideo,1000);
            Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('/facesurvey/models'),
            faceapi.nets.faceExpressionNet.loadFromUri('/facesurvey/models')
            ]).then(record());
            
        }

        function autoStopVideo(){
            if(player.getCurrentTime() >= 20){
                player.stopVideo();
                clearInterval(endVideo);
            }
        }

        var checker;
        var rec;
      
        function record(){
           
            console.log("recording");
            rec = setInterval(doStuff,20);
            checker = setInterval(checktime,100); 
        }

        function sendData(){    // send data to survey
                var target = window.parent;
                var message = "IT WORKS"
                target.postMessage(message,"*");
                console.log("SEND MESSAGE TO PARENT");  
        }

        function checktime(){
          if(player.getCurrentTime() >= timeOfInterest+3 ) {
                clearInterval(checker);
                clearInterval(rec);
                data.forEach(function(item){ 
                    if(item[0] >= timeOfInterest-4 && item[0] <= timeOfInterest+2){
                        relevantData.push(item);
                     }
                });
                    console.log("TESTESTEST");
                    sendData();
                    console.log(data);
                }
        }   

        

        async function doStuff(){
            console.log("doing stuff at " + player.getCurrentTime() + " seconds");     //message for the console

            //const [track] = stream.getVideoTracks();
             // get a single frame from the webcam feed                                                
        //    const imageCapture = new ImageCapture(track);
          /*  const inputImg = await imageCapture.grabFrame(); */
            

          const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 128 });
          const videoEl = $('#camVideo').get(0);
            // get detection result from faceapi
         const result = await faceapi.detectSingleFace(videoEl, options).withFaceExpressions(); 
            
            if(result){ // process detection result and save the data
                const expressionArray = result.expressions.asSortedArray();
                const timestamp = player.getCurrentTime();
                newData = [];
                newData.push(timestamp);
                newData.push(expressionArray)
                data.push(newData);
            } 
        }  
        
        </script>

        <div id="player"></div>
       <button id="btn" disabled onclick="play()">Start</button>  
       <video id="camVideo" autoplay muted style= opacity:0 style=position:static  ></video> 
      <script>
            // HTML Video Code
            
         var video = document.getElementById('camVideo');
            if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {
                video.srcObject = stream;
                video.play();
                });
            }

        

      </script>
       
    </body>

</html>

        